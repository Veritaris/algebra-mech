

%%% 2015

% 17.02.2015

\section{Векторные пространства}\label{section_vector_spaces}

\subsection{Первые определения}
\literature{[F], гл. XII, \S~1, п. 1, \S~2, пп. 1, 2; [K2], гл. 1,
  \S~1; [KM], ч. 1, \S~1; [vdW], гл. 4, \S~19.}

Неформально говоря, векторное пространство~--- это множество, элементы
которого называются векторами, на котором определены операции сложения
векторов и умножения вектора на число, причем выполняются некоторые
естественные свойства этих операций. Здесь <<число>> означает
произвольный элемент некоторого основного поля $k$.
\begin{definition}\label{def:vector_space}
Пусть $k$~--- поле.
Множество $V$ вместе с операциями $+\colon V\times V\to V$,
$\cdot\colon V\times k\to V$ называется \dfn{векторным
  пространством}\index{векторное пространство}
(точнее~--- \dfn{правым векторным пространством}),
если выполняются следующие свойства (называемые {\em аксиомами
  векторного пространства}):
\begin{enumerate}
\item $(u+v)+w=u+(v+w)$ для любых $u,v,w\in V$ ({\em ассоциативность сложения});
\item существует $0\in V$ такой, что $0+v=v+0=v$ для всех $v\in V$
  ({\em нейтральный элемент по сложению});
\item для любого $v\in V$ найдется элемент $-v\in V$ такой, что
  $v+(-v)=(-v)+v=0$ ({\em обратный элемент по сложению=противоположный
    элемент});
\item $u+v=v+u$ для любых $u,v\in V$ ({\em коммутативность сложения});
\item $(u+v)a=u\cdot a+v\cdot a$ для любых $u,v\in V$,
  $a\in k$ ({\em левая дистрибутивность});
\item $u(a+b) = u\cdot a + u\cdot b$ для любых $u\in V$,
  $a,b\in k$ ({\em правая дистрибутивность});
\item $u\cdot(a\cdot b)=(u\cdot a)\cdot b$ для любых $u\in V$,
  $a,b\in k$ ({\em внешняя ассоциативность});
\item $u\cdot 1 = u$ для любого $u\in U$ ({\em унитальность}).
\end{enumerate}
При этом элементы пространства $V$ называются
\dfn{векторами}\index{вектор}, а
элементы поля $k$~--- \dfn{скалярами}\index{скаляр}.
\end{definition}

\begin{remark}
Заметим, что первые три аксиомы не включают в себя умножение на скаляр
и выражают тот факт, что $V$ с операцией сложения является {\em
  группой} (см. определение~\ref{def_group}); четвертая аксиома
означает, что эта группа коммутативна.
\end{remark}
\begin{remark}
Обратите внимание, что знаки $+$ и $\cdot$ в аксиомах используются в
разных смыслах: $+$ может означать сложение как в векторном
пространстве $V$, так и в поле $k$, а $\cdot$ означает умножение
скаляра на вектор и умножение скаляров в поле $k$. Упражнение:
про каждый знак $+$ и $\cdot$ в аксиомах векторного пространства
скажите, какую именно операцию он обозначает.
Символ <<$0$>> также используется в дальнейшем в двух смыслах: он может
обозначать как нулевой элемент поля, так и нулевой элемент векторного
пространства. При желании мы могли бы как-нибудь различать их (некоторые
авторы пишут $\overline{0}$ для нулевого вектора), но
не будем этого делать, поскольку из контекста всегда ясно, какой
элемент имеется в виду (а если не ясно, читатель получает
хорошее упражнение).
\end{remark}
\begin{remark}
Мы постараемся всегда при умножении вектора на скаляр записывать
вектор слева, а вектор справа, то есть, писать $v\cdot a$ для $v\in V$
и $a\in k$. Вместе с тем, можно было бы везде писать $a\cdot v$
вместо $v\cdot a$. Читателю предлагается переписать
определение~\ref{def:vector_space} в таких терминах и убедиться, что
получатся совершенно аналогичные аксиомы (за счет коммутативности
умножения в поле!) Более щепетильные авторы различают две конвенции
в записи и говорят о {\em правых векторных пространствах}
и {\em левых векторных пространствах}, соответственно.
Отметим, что естественное обобщение понятия векторного пространства
на произвольные кольца (не обязательно коммутативные) требует
строгого различения этих двух понятий.
\end{remark}

\begin{examples}
\begin{enumerate}
\item Для натурального $n$ рассмотрим множество всех столбцов высоты
  $n$, состоящих из элементов поля $k$:
  $k^n=\{\begin{pmatrix}a_1 \\ \vdots \\ a_n\end{pmatrix}\mid a_i\in
  k\}$. Введем на $k^n$ естественные операции [покомпонентного]
  сложения и [покомпонентного] умножения на скаляры. Тогда $k^n$
  превратится в векторное пространство над полем $k$: справедливость
  всех аксиом немедленно следует из свойств операций над матрицами,
  поскольку можно рассматривать такие столбцы как матрицы $n\times 1$:
  $k^n=M(n,1,k)$.
\item Аналогично, множество всех строк длины $n$ над $k$ с
  покомпонентными операциями сложения и умножения на скаляры образует
  векторное пространство над $k$; мы будем обозначать его через
  ${}^nk$. Альтернативно, ${}^nk=M(1,n,k)$.
\item Обобщая предыдущие примеры, можно заметить, что множество
  $M(m,n,k)$ всех матриц фиксированного размера $m\times n$ с обычными
  операциями сложения матриц и умножения на скаляры образует векторное
  пространство над $k$.
\item Аналогично первым двум примерам, можно рассмотреть множества столбцов
{\em бесконечной высоты} и строк {\em бесконечной ширины}, состоящих
из элементов поля $k$. И то, и другое~--- это просто множество бесконечных
последовательностей $a_1,a_2,\dots$, где все $a_i$ лежат в $k$.
Различие между множеством столбцов и множеством строк лишь в форме записи.
Множество таких последовательностей, воспринимаемых как столбцы,
мы будем обозначать через $k^\infty$, а множество последовательностей,
воспринимаемых как строки~--- через ${}^{\infty}k$.
На каждом из этих множеств определены операции [покомпонентного]
сложения и [покомпонентного] умножения на элементы поля $k$. Несложно
проверить выполнение для них всех свойств из
определения~\ref{def:vector_space}, поэтому $k^\infty$ и ${}^{\infty}k$
являются векторными пространствами над полем $k$.
\item Пусть $E$~--- множество [свободных] векторов на стандартной
  эвклидовой плоскости. Из школьного курса известно, что сложение
  векторов и умножение векторов на вещественные числа обладает всеми
  свойствами из определения векторного пространства. Поэтому $E$ можно
  рассматривать как векторное пространство над $\mb R$.
  Аналогично, множество векторов в трехмерном пространстве является
  векторным пространством над $\mb R$.
\item Пусть $k\subseteq L$~--- поля. Элементы $L$ можно складывать
  между собой и умножать на элементы поля $k$ (на самом деле, их можно
  перемножать и между собой, но мы забудем про эту операцию). Все
  свойства из определения векторного пространства немедленно следуют
  из свойств операций в поле. Поэтому
  $L$ естественным образом является векторным пространством над
  $k$. Например, $\mb R$~--- векторное пространство над $\mb Q$, а
  $\mb C$~--- векторное пространство над $\mb Q$ и над $\mb R$. Кроме
  того, любое поле является (не очень интересным) векторным
  пространством над самим собой.
\item Многочлены от одной переменной над полем $k$ можно складывать
  между собой и умножать на скаляры из $k$; поэтому $k[x]$ (с
  естественными операциями) является векторным пространством над $k$
  (необходимые аксиомы немедленно следуют из свойств операций в
  $k[x]$).
\end{enumerate}
\end{examples}

\begin{proposition}
Пусть $V$~--- векторное пространство над $k$. Тогда
\begin{enumerate}
\item $v\cdot 0=0$ для любого вектора $v\in V$, где  $0\in k$;
\item $0\cdot a = 0$ для любого скаляра $a\in k$, где $0$~--- нулевой вектор;
\item $v\cdot (-1)=-v$ для любого вектора $v\in V$.
\end{enumerate}
\end{proposition}
\begin{proof}
\begin{enumerate}
\item Заметим, что $v\cdot 0 = v\cdot (0+0) = v\cdot 0 + v\cdot
  0$. Прибавим к обеим частям $-(v\cdot 0)$; получим
  $(-v\cdot 0) + v\cdot 0 = (-v\cdot 0) + v\cdot 0 + v\cdot 0$, откуда
  $0=0+v\cdot 0=v\cdot 0$, что и требовалось.
\item  Заметим, что $0\cdot a = (0+0)\cdot a = 0\cdot a
+ 0\cdot a$. Прибавим к обеим частям $-(0\cdot a)$; получим
$-(0\cdot a) + 0\cdot a = -(0\cdot a) + 0\cdot a
+ 0\cdot a$, откуда $0 = 0 + 0\cdot a = 0\cdot a$,
что и требовалось.
\item Воспользуемся первой частью: $0 = v\cdot 0 = v\cdot (1+(-1)) =
  v\cdot 1 + v\cdot (-1) = v + v\cdot (-1)$. Прибавим к обеим частям
  $(-v)$; получим $-v = (-v) + v + v\cdot (-1) = 0 + v\cdot (-1) =
  v\cdot (-1)$.
\end{enumerate}
\end{proof}

\subsection{Подпространства}

\begin{definition}
Пусть $V$~--- векторное пространство над полем $k$.
Подмножество $U\subseteq V$ называется
\dfn{подпространством}\index{подпространство}, если выполнены следующие условия:
\begin{enumerate}
\item $0\in U$;
\item если $u,v\in U$, то и $u+v\in U$;
\item если $u\in U$, $a\in k$, то $u\cdot a\in U$.
\end{enumerate}
Тот факт, что $U$ является подпространством $V$, мы будем обозначать
так: $U\leq V$.
\end{definition}

\begin{remark}
Если $U\leq V$, то $-u\in U$ для любого $u\in
U$. Действительно, для любого $u\in U$
выполнено $-u = u\cdot (-1)\in U$.
\end{remark}

\begin{examples}
\begin{enumerate}
\item В любом пространстве $V$ есть <<тривиальные>> подпространства
  $0\leq V$ и $V\leq V$.
\item Пусть $V = k[x]$, $U = \{f\in k[x]\mid f(1) = 0\}$. Тогда
$U\leq V$.
\item Пусть $k[x]_{\leq n}$~--- множество многочленов степени не выше
  $n$: $k[x]_{\leq n}=\{f\in k[x]\mid \deg(f)\leq n\}$. Нетрудно
  проверить, что $k[x]_{\leq n}\leq k[x]$.
\item Множество векторов, параллельных некоторой плоскости, является
  подпространством трехмерного пространства векторов.
% добавить пример про все подпространства плоскости и трехмерного пространства!
\end{enumerate}
\end{examples}

\begin{lemma}
Пересечение произвольного набора подпространств пространства $V$
является подпространством в $V$. 
\end{lemma}
\begin{proof}
Пусть $\{U_\alpha\}_{\alpha\in A}$~--- подпространства в
$V$. Пусть $u,v\in\bigcap_{\alpha\in A}U_\alpha$. По определению
пересечения выполнено $u,v\in U_\alpha$ для всех $\alpha$. Так как
$U_\alpha\leq V$, то для каждого $\alpha$ выполнено $u+v\in U_\alpha$,
откуда $u+v\in\bigcap_{\alpha\in A}U_\alpha$. Кроме того, если
$a\in k$, то для каждого $\alpha$ выполнено $ua\in
U_\alpha$, откуда $ua\in\bigcap_{\alpha\in A}U_\alpha$.
\end{proof}

\begin{definition}
Пусть $U_1,\dots,U_m$~--- подпространства в $V$.
\dfn{Суммой} подпространств $U_1,\dots,U_m$ называется множество
всевозможных сумм элементов $U_1,\dots,U_m$.
Обозначение: $U_1+\dots+U_m$.
Более точно,
$$
U_1+\dots+U_m = \{u_1+\dots+u_m\mid u_1\in U_1,\dots,u_m\in U_m\}.
$$
\end{definition}
Несложно проверить (упражнение!), что для любых подпространств
$U_1,\dots,U_m$ в $V$ их сумма $U_1+\dots+U_m$ также является
подпространством в $V$.
\begin{lemma}
Пусть $U_1,\dots,U_m$~--- подпространства векторного пространства $V$.
Тогда их сумма $U_1+\dots+U_m$~--- это наименьшее (по включение)
векторное подпространство в $V$, содержащее каждое из подпространств
$U_1,\dots,U_m$.
\end{lemma}
\begin{proof}
Очевидно, что каждое из подпространств $U_1,\dots,U_m$ содержится
в сумме $U_1+\dots+U_m$ (достаточно рассмотреть суммы
вида $u_1+\dots+u_m$, в которых все элементы, кроме одного, равны нулю).
С другой стороны, если некоторое подпространство пространства $V$
содержит $U_1,\dots,U_m$, то оно обязано содержать и все элементы
вида $u_1+\dots+u_m$ ($u_i\in U_i$), поэтому обязано содержать
$U_1+\dots+U_m$.
\end{proof}

Итак, любой элемент $u\in U_1+\dots+U_m$ можно представить
в виде $u = u_1+\dots+u_m$ для некоторых $u_i\in U_i$.
Нас интересует случай, когда такое представление
{\em единственно}.

\begin{definition}
Пусть $U_1,\dots,U_m$~--- подпространства векторного пространства $V$.
Будем говорить, что $V$ является \dfn{прямой суммой} подпространств
$U_1,\dots,U_m$, если каждый элемент $v\in V$ можно единственным образом
представить в виде суммы $v = u_1+\dots+u_m$, где все $u_i\in U_i$.
Обозначение: $V=U_1\oplus\dots\oplus U_m$ или
$V = \bigoplus_{i=1}^m U_i$.
\end{definition}

\begin{examples}
\begin{enumerate}
\item Пусть $V = k^3$~--- пространство столбцов высоты $3$ над полем $k$,
$U = \{\begin{pmatrix} * \\ * \\ 0 \end{pmatrix}\}$~--- подпространство
столбцов, третья координата которых равна нулю,
$W = \{\begin{pmatrix} 0 \\ 0 \\ * \end{pmatrix}\}$~--- подпространство
столбцов, первые две координаты которых равны нулю.
Тогда $V$ является прямой суммой $U$ и $W$: $V = U\oplus W$.
\item Пусть $V = k^n$~--- пространство столбцов высоты $n$ над полем $k$.
Обозначим через $U_i$ подпространство столбцов в $V$, в которых на всех
местах кроме, возможно, $i$-го, стоит нуль:
$$
U_i = \{\begin{pmatrix}0 \\ \vdots \\ 0 \\ * \\ 0 \\ \vdots \\ 0\end{pmatrix}\}.
$$
Тогда $V = U_1\oplus\dots\oplus U_n$.
\item Пусть теперь снова $V = k^3$, $U_1$~--- множество столбцов вида
$\begin{pmatrix} a \\ a \\ 0\end{pmatrix}$, где $a\in k$;
$U_2$~--- множество столбцов вида
$\begin{pmatrix} b \\ 0 \\ 0\end{pmatrix}$, где $b\in k$;
$U_3$~--- множество столбцов вида
$\begin{pmatrix} 0 \\ c \\ d\end{pmatrix}$, где $c,d\in k$.
Тогда $V$ {\em не является} прямой суммой подпространств $U_1, U_2, U_3$.
Дело в том, что столбец вида $\begin{pmatrix}0 \\ 0 \\ 0\end{pmatrix}$
можно разными способами представить в виде суммы трех векторов $u_1\in U_1$,
$u_2\in U_2$, $u_3\in U_3$. Действительно,
во-первых,
$$
\begin{pmatrix} 0 \\ 0 \\ 0\end{pmatrix}
=
\begin{pmatrix} 1 \\ 1 \\ 0\end{pmatrix} +
\begin{pmatrix} -1 \\ 0 \\ 0\end{pmatrix} +
\begin{pmatrix} 0 \\ -1 \\ 0\end{pmatrix},
$$
а во-вторых, разумеется,
$$
\begin{pmatrix} 0 \\ 0 \\ 0\end{pmatrix}
=
\begin{pmatrix} 0 \\ 0 \\ 0\end{pmatrix} +
\begin{pmatrix} 0 \\ 0 \\ 0\end{pmatrix} +
\begin{pmatrix} 0 \\ 0 \\ 0\end{pmatrix}.
$$
\end{enumerate}
\end{examples}

В последнем примере мы показали, что пространство {\em не является}
прямой суммой данных подпространств, предъявив два различных разложения
для {\em нулевого} вектора. Предположим теперь, что у нас есть набор
подпространств в $V$, сумма которых равна $V$. Следующее предложение
показывает, что для доказательства того, что эта сумма прямая,
достаточно доказать, что $0$ единственным образом представляется
в виде суммы векторов из этих подпространств.

\begin{proposition}\label{prop:direct_sum_zero_criteria}
Пусть $U_1,\dots,U_n$~--- подпространства в $V$.
Пространство $V$ является прямой суммой этих подпространств тогда
и только тогда, когда выполняются два следующих условия:
\begin{enumerate}
\item $V = U_1 + \dots + U_n$;
\item если $0 = u_1 + \dots + u_n$ для некоторых $u_i\in U_i$, то
$u_1 = \dots = u_n = 0$.
\end{enumerate}
\end{proposition}
\begin{proof}
Предположим сначала, что $V = U_1\oplus\dots\oplus V_n$.
Тогда по определению $V = U_1 + \dots + U_n$.
Предположим, что $0 = u_1 + \dots + u_n$, где $u_1\in U_1,\dots,u_n\in U_n$.
Заметим, что также $0 = 0 + \dots + 0$, где $0\in U_1,\dots,0\in U_n$.
Из определения прямой суммы теперь следует, что 
$u_1 = 0,\dots,u_n=0$.

Обратно, пусть выполняются два условия выше, и пусть $v\in V$.
Из первого условия следует, что мы можем записать
$v = u_1 + \dots + u_n$ для некоторых $u_1\in U_1,\dots,u_n\in U_n$.
Осталось доказать, что такое представление единственно.
Если $v = u'_1 + \dots + u'_n$ для $u'_1\in U_1,\dots,u'_n\in U_n$,
то $0 = v - v = (u_1 - u'_1) + \dots + (u_n - u'_n)$, где каждая
разность $u_i - u'_i$ лежит в $U_i$. Из второго условия теперь
следует, что $u_i - u'_i = 0$ для всех $i$, то есть,
что два данных разложения на самом деле совпадают.
\end{proof}

Приведем еще один полезный критерий разложения пространства
в прямую сумму {\em двух} подпространств.

\begin{proposition}\label{prop:direct-sum-criteria-for-2}
Пусть $U,W\leq V$. Пространство $V$ является прямой суммой $U$ и $W$
тогда и только тогда, когда $V = U+W$ и $U\cap W = \{0\}$.
\end{proposition}
\begin{proof}
Предположим, что $V = U\oplus W$. Тогда $V = U + W$ по определению
прямой суммы. Если $v\in U\cap W$, то можно записать
$0 = v + (-v)$, где $v\in U$, $(-v)\in W$. Из единственности представления
$0$ в виде суммы векторов из $U$ и $W$ теперь следует, что $v=0$.
Поэтому $U\cap W = \{0\}$.

Для доказательства обратного утверждения предположим, что $V = U+W$
и $U\cap W = \{0\}$. Пусть $0 = u+w$, где $u\in U$, $w\in W$.
По предложению~\ref{prop:direct_sum_zero_criteria}
нам достаточно доказать, что $u=w=0$. Но из $0=u+w$ следует,
что $u = -w\in W$, в то время $u\in U$. Значит,
$u\in U\cap W$, и потому $u=0$ и $w = -u = 0$, что и требовалось.
\end{proof}

\begin{remark}
Представьте три прямые $U_1$, $U_2$, $U_3$, проходящие через $0$
на эвклидовой плоскости $V$. Очевидно, что $V = U_1 + U_2 + U_3$
и $U_1\cap U_2 = U_2\cap U_3 = U_3\cap U_1 = \{0\}$.
Это значит, что {\em наивное} обобщение предложения~\ref{prop:direct-sum-criteria-for-2}
неверно.
\end{remark}

% 02.03.2015

\subsection{Линейная зависимость и независимость}
\literature{[F], гл. XII, \S~1, п. 2; [K2], гл. 1,
  \S~1, п. 2, \S~2, п. 1; [KM], ч. 1, \S~2; [vdW], гл. 4, \S~19.}

\begin{definition}\label{dfn:linear-combination-and-span}
Пусть $V$~--- векторное пространство над $k$, $v_1,\dots,v_n\in V$ и
$a_1,\dots,a_n\in k$. Выражение вида
$v_1a_1+\dots+v_na_n$ называется \dfn{линейной
  комбинацией}\index{линейная комбинация} элементов
$v_1,\dots,v_n$. Отметим, что иногда линейной
комбинацией называется сама формальная сумма
$v_1a_1+\dots+v_na_n$, а иногда~--- ее значение (то есть,
элемент $V$).
Множество всех линейных комбинаций векторов $v_1,\dots,v_m$
называется их \dfn{линейной оболочкой} и обозначается
через $\la v_1,\dots,v_m\ra$.
Полезно определить линейную оболочку и для бесконечного множества векторов:
пусть $S\subseteq V$~--- произвольное подмножество векторного
пространства $V$. Его линейной оболочкой называется
множество всех линейных комбинаций вида $v_1a_1 + \dots + v_na_n$,
где $v_1,\dots,v_n\in S$. Обозначение: $\la S\ra$.
\end{definition}
\begin{remark}
Нетрудно проверить, что линейная оболочка произвольного подмножества
в $V$ является векторным подпространством в $V$.
Заметим также, что линейная оболочка пустого подмножества
$\varnothing\subset V$ равна тривиальному подпространству $\{0\}$.
\end{remark}

\begin{definition}\label{dfn:spanning-set}
Пусть $V$~--- векторное пространство, $v_1,\dots,v_m\in V$.
Будем говорить, что $v_1,\dots,v_m$~--- \dfn{система образующих}
пространства $V$ (или что векторы $v_1,\dots,v_m$ \dfn{порождают}
пространство $V$, или что пространство $V$ \dfn{порождается}
векторами $v_1,\dots,v_m$), если их линейная оболочка совпадает с $V$:
$\la v_1,\dots,v_m\ra = V$.
Пространство называется \dfn{конечномерным}, если
оно порождается некоторым конечным набором векторов.
Можно определить систему образующих и в случае бесконечного набора
векторов: подмножество $S\subseteq V$ называется \dfn{системой образующих}
пространства $V$, если его линейная оболочка совпадает с $V$.
\end{definition}
\begin{examples}
\begin{enumerate}
\item Пространство столбцов $k^n$ конечномерно. Действительно, обозначим
через $e_i\in k^n$ столбец, у которого в $i$-ой позиции стоит $1$, а
в остальных~--- $0$. Нетрудно проверить, что векторы
$e_1,\dots,e_n$ порождают $k^n$.
\item Пространство многочленов $k[x]$ над полем $k$ не является конечномерным.
Действительно, предположим, что оно порождается некоторым конечным набором
многочленов. Пусть $m$~--- наибольшая из степеней этих многочленов.
Тогда все линейные комбинации элементов нашего набора являются многочленами
степени не выше $m$, и поэтому их множество не совпадает со всем
пространством $k[x]$.
\end{enumerate}
\end{examples}

\begin{definition}
Пространство, не являющееся конечномерным, называется
\dfn{бесконечномерным}. По определению это означает, что
{\em никакой} конечный набор элементов этого пространства не порождает его.
\end{definition}

Пусть $v_1,\dots,v_n\in V$, и пусть $v\in\la v_1,\dots,v_n\ra$. По определению
это означает, что существуют коэффициенты $a_1,\dots,a_n\in k$ такие,
что $v = v_1a_1 + \dots + v_na_n$.
Зададимся вопросом: единственен ли такой набор коэффициентов?
Пусть $b_1,\dots,b_n\in k$~--- еще один набор скаляров, для которого
$v = v_1b_1 + \dots + v_nb_n$.
Вычитая одно равенство из другого, получаем
$0 = v_1(b_1 - a_1) + \dots + v_n(b_n - a_n)$.
Мы записали $0$ как линейную комбинацию векторов $v_1,\dots,v_m$.
Если единственный способ сделать это тривиален (положить все коэффициенты
равными $0$), то $b_i = a_i$ для всех $i$, и поэтому наш набор коэффициентов
$a_1,\dots,a_n$ единственен.

\begin{definition}\label{def:linearly_independent}
Набор векторов $v_1,\dots,v_n\in V$ называется \dfn{линейно независимым},
если из равенства $v_1a_1 + \dots + v_na_n = 0$ следует, что
$a_1 = \dots = a_n$. Назовем выражение вида
$v_1a_1 + \dots + v_na_n$ \dfn{тривиальной линейной комбинацией},
если все ее коэффициенты равны нулю: $a_1 = \dots = a_n$.
Тогда векторы $v_1,\dots,v_n\in V$ линейно независимым если и только если
никакая их нетривиальная линейная комбинация не равна нулю.
В таком виде определение удобно обобщить на произвольное (не обязательно
конечное) множество векторов: подмножество $S\subseteq V$ назовем
\dfn{линейно независимым}, если из того, что некоторая линейная комбинация
векторов $S$ равна нулю, следует, что все ее коэффициенты равны нулю.
\end{definition}

\begin{definition}
Набор векторов $S\subseteq V$, который {\em не является} линейно независимым,
называется \dfn{линейно зависимым}. По определению это означает,
что {\em существует} некоторая нетривиальная линейная комбинация
векторов из $S$, которая равна нулю. Таким образом,
набор $v_1,\dots,v_n\in V$ \dfn{линейно зависим}, если существуют
коэффициенты $a_1,\dots,a_n\in k$, не все из которых равны нулю, такие,
что $v_1a_1 + \dots + v_na_n = 0$
\end{definition}

\begin{remark}
Еще одна полезная переформулировка: набор векторов линейно зависим тогда и только тогда,
когда некоторый вектор из него выражается через остальные (то есть,
лежит в линейной оболочке остальных). Действительно,
если набор $S$ линейно зависим, то существует нетривиальная линейная зависимость
вида $v_1a_1 + \dots + v_na_n = 0$. Нетривиальность означает, что некоторый
ее коэффициент отличен от нуля; без ограничения общности можно считать,
что $a_1\neq 0$. Но тогда $v_1 = -\frac{a_2}{a_1}v_2 - \dots - \frac{a_n}{a_1}v_n$.
Обратное следствие очевидно. Упражнение: проверьте,
что наша переформулировка работает и для <<вырожденных>> случаев
наборов из одного вектора.
\end{remark}

\begin{remark}
Рассуждение перед определением~\ref{def:linearly_independent} показывает,
что набор $v_1,\dots,v_n$ линейно независим тогда и только тогда,
когда у каждого вектора из линейной оболочки $\la v_1,\dots,v_n\ra$ есть
только одно представление в виде линейной комбинации векторов
$v_1,\dots,v_n$. Аналогично, линейная независимость
произвольного подмножества $S\subseteq V$ означает, что
у каждого вектора из линейной оболочки $\la S\ra$ есть только
одно представление в виде линейной комбинации векторов из $S$.
\end{remark}

\begin{examples}
\begin{enumerate}
\item Набор из трех векторов
$\begin{pmatrix}1 \\ 0 \\ 0 \\ 0\end{pmatrix},
\begin{pmatrix}0 \\ 0 \\ 1 \\ 0\end{pmatrix},
\begin{pmatrix}0 \\ 0 \\ 0 \\ 1\end{pmatrix} \in k^4$
линейно независим. Действительно, их линейная комбинация с коэффициентами
$a_1,a_2,a_3$ равна $\begin{pmatrix} a_1 \\ 0 \\ a_2 \\ a_3\end{pmatrix}$,
и из равенства нулю этого вектора следует, что $a_1 = a_2 = a_3$.
\item Пусть $n$~--- произвольное натуральное число.
Тогда набор $1,x,x^2,\dots,x^n$ линейно независим в пространстве
многочленов $k[x]$ (упражнение!). Более того, бесконечное множество
$\{1,x,x^2,\dots,x^n,\dots\}$ линейно независимо в $k[x]$.
\item Любое множество векторов, содержащее нулевой вектор, линейно зависимо.
\item Набор из одного вектора $v\in V$ линейно независим тогда и только тогда,
когда $v\neq 0$.
\item Набор из двух векторов $u,v\in V$ линейно независим тогда и только тогда,
когда ни один из них не получается из другого умножением на скаляр
(почему?).
\end{enumerate}
\end{examples}

\begin{lemma}\label{lemma_lnz_lz_up_down}
Пусть $V$~--- векторное пространство, $X\subseteq Y\subseteq V$. Если
$Y$ линейно независимо, то и $X$ линейно независимо. Если $X$ линейно
зависимо, то и $Y$ линейно зависимо.
\end{lemma}
\begin{proof}
Очевидно.
\end{proof}

Следующая лемма окажется чрезвычайно полезной. Она утверждает, что если
имеется линейно зависимый набор векторов, в котором первый вектор отличен
от нуля, то один из векторов набора выражается через предыдущие;
тогда его можно выбросить, не изменив линейную оболочку набора.

\begin{lemma}[о линейной зависимости]\label{lemma:linear-dependence-lemma}
Пусть набор $(v_1,\dots,v_n)$ векторов пространства $V$ линейно зависим, и
$v_1\neq 0$. Тогда существует индекс $j\in\{2,\dots,n\}$ такой, что
\begin{itemize}
\item $v_j\in\la v_1,\dots,v_{j-1}\ra$;
\item $\la v_1,\dots,v_n\ra = \la v_1,\dots,\widehat{v_j},\dots,v_n\ra$.
\end{itemize}
\end{lemma}
\begin{proof}
По условию найдутся $a_1,\dots,a_n\in k$ такие, что
$v_1a_1+\dots+v_na_n = 0$.
Пусть $j$~--- наибольший индекс, для которого $a_j\neq 0$.
Тогда
$$
v_j = - \frac{a_1}{a_j}v_1 - \dots - \frac{a_{j-1}}{a_j}v_{j-1},
$$
и первый пункт доказан. Очевидно, что
$\la v_1,\dots,\widehat{v_j},\dots,v_n\ra\subseteq\la v_1,\dots,v_n\ra$.
Покажем обратное включение. Пусть $u\in \la v_1,\dots,v_n\ra$. 
Это означает, что $u = v_1c_1 + \dots + v_nc_n$ для некоторых
$c_1,\dots,c_n\in k$. Заменим в правой части
вектор $v_j$ на его выражение через $v_1,\dots,v_{j-1}$; получим,
что $u$ есть линейная комбинация векторов $v_1,\dots,\widehat{v_j},\dots,v_n$,
что и требовалось.
\end{proof}

\begin{corollary}\label{cor:lnz-becomes-lz}
Пусть набор векторов $v_1,\dots,v_n$ линейно независим, и $v\in V$.
Набор $v_1,\dots,v_n,v$ линейно зависим тогда и только тогда,
когда $v$ лежит в $\la v_1,\dots,v_n\ra$.
\end{corollary}
\begin{proof}
Если набор $v_1,\dots,v_n,v$ линейно зависим, то
(по лемме~\ref{lemma:linear-dependence-lemma}) некоторый вектор в нем
выражается через предыдущие. Это не может быть один из $v_1,\dots,v_n$
в силу линейной независимости $v_1,\dots,v_n$
\end{proof}

Следующая теорема играет ключевую роль в изучении линейно независимых
и порождающих систем. 

\begin{theorem}\label{thm:independent-set-smaller-than-generating}
В конечномерном векторном пространстве количество элементов в любом линейно независимом
множестве не превосходит количества элементов в любом порождающем множестве.
Иными словами, если $u_1,\dots,u_m$ линейно независимые векторы пространства $V$,
и $\la v_1,\dots,v_n\ra = V$, то $m\leq n$.
\end{theorem}
\begin{proof}
Опишем процесс, на каждом шаге которого мы заменяем один
вектор из $\{v_i\}$ на один вектор из $\{u_j\}$.
Заметим сначала, что при добавлении к $v_1,\dots,v_n$ любого вектора
мы получим линейно зависимую систему. В частности, набор
$u_1,v_1,\dots,v_n$ линейно зависим. По лемме~\ref{lemma:linear-dependence-lemma}
мы можем выкинуть из этого набора один из векторов $v_1,\dots,v_n$
(скажем, $v_j$) так,
что оставшиеся векторы все еще будут порождать $V$.
Мы получили набор вида $u_1,v_1,\dots,\widehat{v_j},\dots,v_n$, порождающий $V$.
Снова заметим, что при добавлении к нему любого вектора мы получим линейно зависимую
систему. В частности, система $u_1,u_2,v_1,\dots,\widehat{v_j},\dots,v_n$ линейно зависима.
По лемме~\ref{lemma:linear-dependence-lemma} какой-то вектор в ней выражается через предыдущие.
Понятно, что это не $u_2$: это бы означало, что $u_1,u_2$ линейно зависимы.
Значит, это один из $v_i$. Лемма~\ref{lemma:linear-dependence-lemma} утверждает, что его
можно выбросить, и оставшиеся векторы все еще будут порождать $V$.

Теперь ясно, что мы можем продолжать этот процесс: на $i$-ом шаге у нас есть
порождающий набор $u_1,\dots,u_{i-1},v_{j_1},\dots$ длины $n$. Добавим к нему вектор $u_i$,
поместив его после $u_{i-1}$, и получим линейно зависимый набор
$u_1,\dots,u_i,v_{j_1},\dots$. По лемме~\ref{lemma:linear-dependence-lemma} некоторый
вектор из этого набора выражается через предыдущие. Это не может быть один из векторов
$u_1,\dots,u_i$ в силу линейной независимости набора $u_1,\dots,u_m$.
Поэтому это один из $v_i$; его можно выбросить и линейная оболочка набора не изменится.

Заметим теперь, что на каждом шаге мы заменяем один вектор из $v_i$ на один вектор
из $u_j$.
Если же $m>n$, это означает, что после $n$-го шага мы получили порождающий набор
вида $u_1,\dots,u_n$. Добавляя вектор $u_{n+1}$ мы должны получить линейно зависимый
набор, который в то же время является подмножеством линейно независимого набора
$u_1,\dots,u_m$, чего не может быть.
\end{proof}

\begin{proposition}\label{prop:subspace-of-fin-dim-is-fin-dim}
Любое подпространство конечномерного векторного пространства конечномерно.
\end{proposition}
\begin{proof}
Пусть $V$~--- конечномерное пространство, $U\leq V$. Построим цепочку
векторов $v_1,v_2,\dots$ следующим образом.
Заметим для начала, что если $U = \{0\}$, то $U$ конечномерно и доказывать
нечего. Если же $U\neq \{0\}$, выберем ненулевой вектор $v_1\in U$.
Очевидно, что $\la v_1\ra\subseteq U$.
Если на самом деле $\la v_1\ra = U$, то доказательство окончено. Иначе
можно выбрать $v_2\in U$ так, что $v_2\notin\la v_1\ra$.
Теперь мы получили набор $v_1,v_2$, и $\la v_1,v_2\ra\subseteq U$.
Продолжим процесс: на $i$-ом шаге у нас есть набор $v_1,\dots,v_{i-1}$ такой,
что $\la v_1,\dots,v_{i-1}\ra\subseteq U$. Если на самом деле имеет место равенство,
то $U$ конечномерно, что и требовалось. Если нет~--- выберем
$v_i\in U$ так, что $v_i\notin\la v_1,\dots,v_{i-1}$. Заметим, что
на каждом шаге мы получаем линейно независимый набор. Действительно,
если векторы $v_1,\dots,v_i$ линейно зависимы, то по лемме~\ref{lemma:linear-dependence-lemma}
какой-то из них выражается через предыдущие, что невозможно в силу выбора
каждого вектора.
Но по теореме~\ref{thm:independent-set-smaller-than-generating} длина
этого линейно независимого набора векторов пространства $V$ не превосходит
количества элементов в некотором (конечном) порождающем множестве (которое
существует по предположению теоремы). Поэтому описанный процесс не может
продолжаться бесконечно.
\end{proof}

\subsection{Базис}
\literature{[F], гл. XII, \S~1, п. 2; [K2], гл. 1,
  \S~2, п. 1--2; [KM], ч. 1, \S~2; [vdW], гл. 4, \S~20.}

\begin{definition}
Пусть $V$~--- векторное пространство над полем $k$.
Набор векторов называется \dfn{базисом} пространства $V$,
если он одновременно линейно независим и порождает $V$.
\end{definition}

Неформально говоря, линейно независимые наборы векторов очень
<<маленькие>>, а системы образующих~--- <<большие>>. На стыке этих
двух плохо совместимых свойств возникает понятие базиса. Сейчас мы
сформулируем и докажем несколько эквивалентных переформулировок
понятия базиса.

\begin{theorem}\label{thm:basis-equiv}
Подмножество $\mc B\subseteq V$ является базисом тогда и только тогда,
когда любой вектор $V$ представляется в виде линейной комбинации
элементов из $\mc B$, причем единственным образом.
\end{theorem}
\begin{proof}
Если $\mc B$~--- базис, то по определению системы образующих любой
вектор из $V$ представляется в виде линейной комбинации элементов из
$\mc B$. Если таких представления у вектора $v\in V$ два, например,
$u_1a_1+\dots+u_na_n = v = u_1b_1+\dots+u_nb_n$ для
некоторых $u_i\in\mc B$, $a_i,b_i\in k$, то
$u_1(a_1-b_1)+\dots+u_n(a_n-b_n)=0$, и из линейной
независимости $\mc B$ следует, что все коэффициенты в этой линейной
комбинации равны $0$, откуда $a_i=b_i$ для всех $i$, и на
самом деле два представления вектора $v$ совпадают.

Обратно, если любой вектор $V$ представляется в виде линейной
комбинации элементов из $\mc B$ единственным образом, то $\mc B$
является системой образующих, и если она линейно зависима, то имеется
нетривиальная линейная комбинация
$v_1a_1+\dots+v_na_n=0=v_1\cdot 0+\dots+v_n\cdot 0$. Мы
получили два различных представления одного вектора $0\in V$ (они
различны, поскольку не все $a_i$ равны нулю)~--- противоречие.
\end{proof}

\begin{theorem}\label{thm:spanning-list-contains-basis}
Из любой конечной системы образующих пространства $V$ можно выбрать
базис.
\end{theorem}
\begin{proof}
Пусть $v_1,\dots,v_n$~--- система образующих пространства $V$.
Сейчас мы выбросим из нее некоторые векторы так, чтобы она стала базисом $V$.
А именно, последовательно для $j=1,2,\dots,n$, мы выбросим
$v_j$, если $v_j\in\la v_1,\dots,v_{j-1}\ra$. Заметим, что при каждом выбрасывании
линейная оболочка векторов не меняется, поскольку мы выбрасываем только такие векторы,
которые выражаются через предыдущие. Покажем, что полученный в итоге
набор векторов линейно независим. Если он линейно зависим, то
по лемме~\ref{lemma:linear-dependence-lemma} там найдется вектор, лежащий
в линейной оболочке предыдущих; но такой вектор был бы выкинут в процессе.
Заметим, что лемму~\ref{lemma:linear-dependence-lemma} можно применить, поскольку
первый вектор в нашем наборе обязан быть ненулевым: линейная оболочка пустого
набора равна $\{0\}$.
\end{proof}

% 16.03.2015

\begin{corollary}\label{cor:a-basis-exists}
В любом конечномерном пространстве есть базис.
\end{corollary}
\begin{proof}
По определению, в конечномерном пространстве есть конечная система образующих.
По теореме~\ref{thm:spanning-list-contains-basis} из нее можно выбрать базис.
\end{proof}

\begin{remark}
На самом деле, базис есть в любом пространстве, даже бесконечномерном.
Доказательство этого факта, однако, требует тонкого рассуждения
с использованием {\em аксиомы выбора}\index{аксиома выбора}
(см. замечание~\ref{remark:axiom-of-choice}
в недрах доказательства теоремы~\ref{thm:sur-inj-reformulations}),
поэтому мы воздержимся от него. В нашем курсе речь будет вестись только
о конечномерных пространствах; формулировки для бесконечномерных пространств
мы приводим только тогда, когда они в точности повторяют формулировки
в конечномерном случае.
\end{remark}

Следующая теорема в некотором смысле двойственна
теореме~\ref{thm:spanning-list-contains-basis}.
\begin{theorem}\label{thm:li-contained-in-a-basis}
Любой линейно независимый набор векторов в конечномерном пространстве
можно дополнить до базиса.
\end{theorem}
\begin{proof}
Пусть $u_1,\dots,u_m$~--- линейно независимая система векторов пространства $V$,
и пусть $v_1,\dots,v_n$~--- произвольная порождающая система пространства $V$
(она существует по определению конечномерности).
Положим для начала $\mc B = \{u_1,\dots,u_m\}$ и
проделаем следующую процедуру последовательно для $j=1,\dots,n$:
если вектор $v_j$ не лежит в линейной оболочке $\la\mc B\ra$ множества $\mc B$,
то добавим его к $\mc B$; а если лежит~--- пропустим. Заметим, что
после каждого такого шага множество $\mc B$ все еще линейно независимо
(следствие~\ref{cor:lnz-becomes-lz}). После $n$-го шага мы получим,
что {\em каждый} из векторов $v_1,\dots,v_n$ лежит в $\la\mc B\ra$.
Но тогда и любой вектор, выражающийся через $v_1,\dots,v_n$, лежит
в $\la\mc B\ra$. Поэтому $\la\mc B\ra = V$.
\end{proof}

В качестве применения теоремы~\ref{thm:li-contained-in-a-basis} приведем следующий
полезный результат.
\begin{proposition}
Пусть $V$~--- конечномерное пространство, $U\leq V$. Тогда существует
подпространство $W\leq V$ такое, что $U\oplus W = V$.
\end{proposition}
\begin{proof}
По предложению~\ref{prop:subspace-of-fin-dim-is-fin-dim} пространство $U$
конечномерно. По следствию~\ref{cor:a-basis-exists} в нем есть базис,
скажем, $u_1,\dots,u_m$. Система векторов $u_1,\dots,u_m$ в пространстве
$V$ линейно независима; по теореме~\ref{thm:li-contained-in-a-basis}
ее можно дополнить до базиса. Этот базис имеет вид
$u_1,\dots,u_m,w_1,\dots,w_n$ для некоторых векторов $w_1,\dots,w_n\in V$.
Пусть $W = \la w_1,\dots,w_n\ra$. Покажем, что $U\oplus W = V$.
По предложению~\ref{prop:direct-sum-criteria-for-2} для этого достаточно
проверить, что $U + W = V$ и $U\cap W = \{0\}$.

Покажем сначала, что $U + W = V$.
Пусть $v\in V$; поскольку $u_1,\dots,u_m,w_1,\dots,w_n$~--- базис $V$,
можно записать
$v = u_1a_1 + \dots + u_ma_m + w_1b_1 + \dots + w_nb_n$
для некоторых скаляров $a_i,b_j\in k$.
Обозначим $u = u_1a_1 + \dots + u_ma_m$, $w = w_1b_1 + \dots + w_nb_n$;
тогда $v = u+w$, причем $u\in U$, $w\in W$.

Пусть теперь $v\in U\cap W$. Тогда существуют скаляры $a_i,b_j\in k$
такие, что $v = u_1a_1 + \dots + u_ma_m = w_1b_1 + \dots + w_nb_n$.
Но тогда $u_1a_1 + \dots + u_ma_m - w_1b_1 - \dots - w_nb_n = 0$~---
линейная комбинация, равная нулю. Из линейной независимости
нашего набора следует, что все ее коэффициенты равны нулю,
а потому и $v=0$.
\end{proof}


\subsection{Размерность}
\literature{[F], гл. XII, \S~1, п. 2; [K2], гл. 1,
  \S~2, п. 1--2; [KM], ч. 1, \S~2; [vdW], гл. 4, \S~19.}

Мы говорили о {\em конечномерных} пространствах, не зная, что такое
{\em размерность}. Как же определить размерность векторного пространства?
Интуитивно понятно, что размерность пространства столбцов $k^n$ должна равняться $n$.
Заметим, что столбцы
$$
\begin{pmatrix}
1 \\ 0 \\ \vdots \\ 0
\end{pmatrix},
\begin{pmatrix}
0 \\ 1 \\ \vdots \\ 0
\end{pmatrix},\dots,
\begin{pmatrix}
0 \\ 0 \\ \vdots \\ 1
\end{pmatrix}
$$
образуют базис в $k^n$. Поэтому хочется определить размерность пространства $V$
как количество элементов в базисе $V$. Но возникает проблема: в {\em каком} базисе?
Конечномерное пространство $V$ может иметь много различных базисов,
и могло бы оказаться, что у него есть базисы разной длины.
Следующая теорема утверждает, что этого не происходит.

\begin{theorem}\label{thm:bases-have-equal-cardinality}
Пусть $V$~--- конечномерное векторное пространство. В любых двух
базисах $V$ поровну элементов.
\end{theorem}
\begin{proof}
Пусть $\mc B_1$, $\mc B_2$~--- два [конечных] базиса $V$.
Тогда $\mc B_1$~--- линейно независимая система, а $\mc B_2$~--- порождающая
система; по теореме~\ref{thm:independent-set-smaller-than-generating}
количество элементов в $\mc B_1$ не больше, чем в $\mc B_2$.
С другой стороны, $\mc B_2$~--- линейно независимая система,
а $\mc B_1$~--- порождающая, поэтому количество элементов
в $\mc B_2$ не больше, чем в $\mc B_1$. Поэтому в них поровну элементов.
\end{proof}

\begin{definition}
Пусть $V$~--- конечномерное векторное пространство над полем
$k$. Количество элементов в любом его базисе называется
\dfn{размерностью}\index{размерность} пространства $V$ и обозначается
через
$\dim_kV$ или просто через $\dim V$. Если же в $V$ нет конечной
системы образующих, то любой 
базис $V$ содержит бесконечное число элементов; в этом случае мы пишем 
$\dim_kV=\infty$ и говорим, что пространство $V$
\dfn{бесконечномерно}\index{векторное пространство!бесконечномерное}.
\end{definition}

\begin{proposition}\label{prop:dimension_is_monotonic}
Пусть $V$~--- конечномерное векторное пространство над $k$ и
$U<V$. Тогда $\dim_kU\leq\dim_kV$. Более того, $\dim_kU=\dim_kV$ тогда
и только тогда, когда $U=V$.
\end{proposition}
\begin{proof}
Пусть $n=\dim_kV$ и $\mc B$~--- некоторый базис $U$. Заметим, что
$\mc B$~--- линейно независимая система векторов в пространстве
$V$. По теореме~\ref{thm:li-contained-in-a-basis} ее можно дополнить
до базиса $V$. Значит, $|\mc B| = \dim_k U$ не превосходит размерности $V$.

Если при этом $\dim_kU = \dim_kV$, то это дополнение должно быть того
же размера, что и само множество $\mc B$. Это означает,
что $\mc B$ является базисом всего пространства $V$,
значит, $U = \la\mc B\ra = V$. Обратное очевидно: если $U = V$,
то $\dim_k U = \dim_k V$.
\end{proof}

Представим, что перед нами [конечный] набор векторов
пространства $V$. Как показать, что он образует базис?
Можно действовать по определению и проверить два факта:
\begin{itemize}
\item этот набор линейно независим;
\item этот набор порождает $V$.
\end{itemize}
Оказывается, из теорем~\ref{thm:spanning-list-contains-basis}
и~\ref{thm:li-contained-in-a-basis}
(вместе с теоремой~\ref{thm:bases-have-equal-cardinality}) следует, что проверку любого
одного из этих пунктов можно опустить, если мы уже знаем, что
в нашем наборе нужное количество элементов: столько, какова
размерность пространства $V$. Разумеется, для этого мы должны
заранее знать эту размерность.
\begin{proposition}\label{prop:right-dim-implies-basis}
Пусть $V$~--- конечномерное векторное пространство.
Любая система образующих $V$ длины $\dim(V)$ является базисом $V$.
Любая линейно независимая система длины $\dim(V)$ является
базисом $V$.
\end{proposition}
\begin{proof}
По теореме~\ref{thm:spanning-list-contains-basis} из
системы образующих можно выбрать базис. Поскольку этот базис
должен иметь длину $\dim(V)$, как и исходная система, то
она сама является базисом.
Аналогично, по теореме~\ref{thm:li-contained-in-a-basis} любую
линейно независимую систему можно дополнить до базиса.
Поскольку в ней уже
столько же элементов, сколько в любом базисе, это дополнение
должно быть пустым. Значит, она сама является базисом.
\end{proof}

Следующая теорема выражает размерность суммы подпространств
через размерности самих подпространств и их пересечения.
\begin{theorem}[Грассмана]
Пусть $U_1,U_2\leq V$. Тогда
$$
\dim(U_1+U_2) = \dim(U_1) + \dim(U_2) - \dim(U_1\cap U_2).
$$
\end{theorem}
\begin{proof}
Пусть $\{u_1,\dots,u_m\}$~--- произвольный базис пространства
$U_1\cap U_2$ (и, таким образом, $m = \dim(U_1\cap U_2$).
Система $\{u_1,\dots,u_m\}$ линейно независима как набор
векторов в $U_1$, и поэтому ее можно дополнить до базиса:
пусть $\{u_1,\dots,u_m,v_1\,dots,v_l\}$~--- базис $U_1$.
Аналогично, система $\{u_1,\dots,u_m\}$ линейно независима
как набор векторов в $U_2$, и поэтому ее можно дополнить
до базиса пространства $U_2$: пусть
$\{u_1,\dots,u_m,w_1,\dots,w_n\}$~--- этот базис.

Покажем, что
набор $\mc B = \{u_1,\dots,u_m,v_1,\dots,v_l,w_1,\dots,w_n\}$
является базисом пространства $U_1+U_2$.
Это система образующих: действительно, любой вектор в $U_1+U_2$
по определению есть сумма вектора из $U_1$ и вектора из $U_2$,
и каждый из этих двух векторов есть линейная комбинация
векторов из $\mc B$. Поэтому $\la\mc B\ra$ содержит $U_1+U_2$;
с другой стороны, все векторы из $\mc B$ лежат в $U_1+U_2$,
поэтому на самом деле $\la\mc B\ra = U_1 + U_2$.

Осталось проверить, что множество $\mc B$ линейно независимо.
Предположим, что $u_1a_1+\dots+u_ma_m + v_1b_1+\dots+v_lb_l +
w_1c_1+\dots +w_nc_n = 0$. Перепишем это равенство:
$$
w_1c_1+\dots+w_nc_n = -u_1a_1-\dots-u_ma_m - v_1b_1-\dots-v_lb_l.
$$
Заметим, что левая часть лежит в $U_2$, а правая лежит в $U_1$.
Поэтому $w_1c_1+\dots+w_nc_n\in U_1\cap U_2$. Мы знаем базис
в $U_1\cap U_2$~--- это $\{u_1,\dots,u_m\}$. Поэтому
$$
w_1c_1 + \dots + w_nc_n = u_1d_1+\dots+u_md_m.
$$
Но набор векторов $\{u_1,\dots,u_m,w_1,\dots,w_n\}$
линейно независим; поэтому из последнего равенства следует,
что все коэффициенты в нем равны 0.
В частности, $c_1=\dots=c_n=0$.
Поэтому наша исходная линейная зависимость имеет вид
$$
u_1a_1+\dots+u_ma_m + v_1b_1+\dots+v_lb_l = 0.
$$
Но набор $\{u_1,\dots,u_m,v_1,\dots,v_l\}$ также линейно
независим, и потому $a_1 = \dots = a_m = v_1 = \dots = v_l = 0$;
значит, исходная линейная комбинация тривиальна,
что и требовалось.
\end{proof}

\begin{corollary}\label{cor:direct-sum-dimension}
Если $V = U_1\oplus U_2$, то $\dim(V) = \dim(U_1)+\dim(U_2)$.
\end{corollary}
\begin{proof}
Очевидно.
\end{proof}

\begin{proposition}
Пусть пространство $V$ конечномерно, и $U_1,\dots,U_m$~--- его
подпространства такие, что $V = U_1 + \dots + U_m$
и $\dim(V) = \dim(U_1) + \dots + \dim(U_m)$.
Тогда $V = U_1\oplus \dots \oplus U_m$.
\end{proposition}
\begin{proof}
Выберем базис в каждом подпространстве $U_i$. Объединение этих
базисов является порождающей системой векторов в $V$
(поскольку $V$ является суммой $U_i$), а их количество
равно размерности $V$. По предложению~\ref{prop:right-dim-implies-basis}
он является базисом в $V$. Обозначим этот базис через $\mc B$.
По определению прямой суммы нам нужно доказать, что если
$0 = u_1+\dots+u_m$ для некоторых $u_i\in U_i$, то $u_1=\dots=u_m=0$.
Разложим каждый вектор $u_i$ по выбранному базису пространства
$U_i$~--- мы получим некоторую линейную комбинацию элементов
базиса $\mc B$. Из ее равенства нулю следует, что все ее коэффициенты
равны нулю, а потому и все $u_i$ равны нулю, что и требовалось.
\end{proof}
